# ASL (American Sign Language) Gesture Recognition Project

A deep learning project for detecting and recognizing American Sign Language gestures using computer vision and neural networks.

## ğŸ“‹ Project Overview

This project implements a Convolutional Neural Network (CNN) to recognize ASL hand gestures in real-time. The model is trained on a dataset of ASL gesture images and can classify different sign language letters.

## ğŸš€ Features

- **Real-time ASL gesture detection** using webcam
- **CNN-based classification** with high accuracy
- **Data preprocessing and augmentation** pipeline
- **Model training and evaluation** scripts
- **Pre-trained models** for immediate use

## ğŸ“ Project Structure

```
ASL_Detection/
â”œâ”€â”€ trainmodel1.ipynb          # Main training notebook
â”œâ”€â”€ realtimedetection.py       # Real-time detection script
â”œâ”€â”€ collectdata.py            # Data collection utility
â”œâ”€â”€ split.py                  # Dataset splitting utility
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ signlanguagedetectionmodel48x48.h5    # Trained model (48x48)
â”œâ”€â”€ signlanguagedetectionmodel48x48.json  # Model architecture
â””â”€â”€ README.md                 # Project documentation
```


## ğŸ“¦ Dependencies

- TensorFlow 2.19.1
- Keras 3.11.3
- OpenCV (opencv-contrib-python)
- NumPy
- Matplotlib
- Other dependencies listed in `requirements.txt`

## ğŸ¯ Usage

### Training the Model

1. **Open the training notebook:**
   ```bash
   jupyter notebook trainmodel1.ipynb
   ```

2. **Follow the notebook cells** to:
   - Load and preprocess the dataset
   - Configure the CNN architecture
   - Train the model
   - Evaluate performance

### Real-time Detection

1. **Run the real-time detection script:**
   ```bash
   python realtimedetection.py
   ```

2. **Use your webcam** to show ASL gestures and see real-time predictions

### Data Collection

1. **Collect new training data:**
   ```bash
   python collectdata.py
   ```

## ğŸ§  Model Architecture

The CNN model uses:
- **Input**: 48x48 grayscale images
- **Convolutional layers** with ReLU activation
- **MaxPooling layers** for dimensionality reduction
- **Dropout layers** for regularization
- **Dense layers** for classification
- **Output**: Softmax layer for multi-class classification

## ğŸ“Š Dataset

The model is trained on ASL gesture images with:
- **Image size**: 48x48 pixels
- **Color format**: Grayscale
- **Classes**: Multiple ASL letters/gestures
- **Training/Validation split**: Configured in the training notebook

## ğŸ”§ Configuration

Key configuration parameters:
- **Batch size**: 128
- **Image size**: 48x48
- **Color mode**: Grayscale
- **Optimizer**: [Add optimizer used]
- **Learning rate**: [Add learning rate]


